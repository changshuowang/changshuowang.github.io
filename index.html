<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Changshuo Wang (王昌硕)</title>
  
  <meta name="author" content="Changshuo Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.jpg">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
	        <name>Changshuo Wang (王昌硕)</name>
              </p>

              <p> 
		 I am currently a <b>Research Fellow</b> at Nanyang Technological University (<b>NTU</b>) (since September 2023). In June 2023, I obtained my doctoral degree from the University of Chinese Academy of Sciences (<b>UCAS</b>) and the Institute of Semiconductors, Chinese Academy of Sciences (<b>CAS</b>), advised by Prof. <a href="https://people.ucas.ac.cn/~liweijun"> Weijun Li </a> and <a href="https://people.ucas.edu.cn/~0023650"> Wanang Xiao </a>. In 2018, I obtained my B.Eng. in the institute of automation, Qingdao University of science and technology (<b>QUST</b>).
              </p>
              <p>
              I am interested in computer vision and deep learning. My current research focuses on:
                <li style="margin: 5px;" >
                  <b>2D/3D scene understanding and generation</b> based on multimodal data; 
                </li>
		<li style="margin: 5px;" >
		  <b>Human-centered visual understanding</b>, such as person re-identification;
		</li>
                <li style="margin: 5px;" >
                  <b>Brain-inspired visual cognition algorithm</b>.
                </li>
              </p>
              <p style="text-align:center">
                <a href="mailto:wangchangshuo1@gmail.com">Email</a> &nbsp/&nbsp
                <a href="files/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/changshuowang"> Github </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:50%;max-width:50%" alt="profile photo" src="images/wcs.jpg">
            </td>
          </tr>
        </tbody></table>
	      
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<tbody>
<b style="color:red;">Note</b><b>: we are hosting a special issue in <a href="https://www.mdpi.com/journal/electronics"> Electronics</a> titled "<a href="https://www.mdpi.com/journal/electronics/special_issues/X61S4L07DK">Recent Progress in Visual AI: Architectures, Learning, and Applications</a>." I am currently serving as a guest editor and warmly invite everyone to submit their contributions!</b>
</tbody>
</table>

	      
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		  <tr>
		  <td style="padding:20px;width:100%;vertical-align:middle">
		    <heading> <font color: #527bbd> News </font> </heading>
		    <p>
			<li style="margin: 5px;" >
			<b>2024-08:</b> <a href="https://www.sciencedirect.com/science/article/pii/S0893608024005501">3DeNet</a> is accepted by <a href="https://www.sciencedirect.com/journal/neural-networks">Neural Networks</a>.
		        </li>
			<li style="margin: 5px;" >
			<b>2024-08:</b> <a href="https://www.sciencedirect.com/science/article/pii/S0263224124013551">DIECED</a> is accepted by <a href="https://www-sciencedirect-com.remotexs.ntu.edu.sg/journal/measurement">Measurement</a>.
		        </li>
			    
			<li style="margin: 5px;" >
			<b>2024-07:</b> <a href="https://github.com/changshuowang/GPSFormer">GPSFormer</a> is accepted by <a href="https://eccv2024.ecva.net/">ECCV</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2024-03:</b> <a href="https://ieeexplore.ieee.org/abstract/document/10462543/">PointGT</a> is accepted by <a href="www.signalprocessingsociety.org/tmm/">TMM</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2024-01:</b> <a href="https://ieeexplore.ieee.org/abstract/document/10415089/">MV-3DSReID</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">TCSVT</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2023-11:</b> <a href="https://www.sciencedirect.com/science/article/pii/S0893608023006263">EIE</a> is accepted by <a href="https://www.sciencedirect.com/journal/neural-networks">Neural Networks</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2023-11:</b> <a href="https://ieeexplore.ieee.org/abstract/document/10528609">LTTPoint</a> is accepted by <a href="https://www.acaitconf.com/">2023 7th Asian Conference on Artificial Intelligence Technology (ACAIT)</a>.
		      </li>	    		    
		      <li style="margin: 5px;" >
			<b>2023-10:</b> A <a href="https://www.sciencedirect.com/science/article/pii/S0957417423029214">survey</a> about occluded person Re-ID is accepted by <a href="https://www.sciencedirect.com/journal/expert-systems-with-applications">Expert Systems with Applications</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2023-10:</b> <a href="https://ieeexplore.ieee.org/abstract/document/10301577">PointReIDNet</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">TCSVT</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2023-06:</b> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0141938223001002">CECC </a> is accepted by <a href="https://www.sciencedirect.com/journal/displays">Displays</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2023-05:</b> A <a href="https://www.sciencedirect.com/science/article/abs/pii/S0141938223000896">survey</a> about point cloud classfication is accepted by <a href="https://www.sciencedirect.com/journal/displays">Displays</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2022-04:</b> The chinese journal version of <a href="http://www.jos.org.cn/jos/article/abstract/6683">DC-CNN</a> is accepted by <a href="https://www.jos.org.cn/jos/home">Journal of software</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2022-04:</b> <a href="https://ieeexplore.ieee.org/document/9762976">SC-CNN</a> are accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">TGRS</a>.
		      </li>
		      <li style="margin: 5px;" >
			<b>2021-09:</b> A survey on RGBD semantic segmentation <a href="https://www.sciencedirect.com/science/article/abs/pii/S014193822100086X"></a> is accepted by <a href="https://www.sciencedirect.com/journal/displays">Displays</a>.
		      </li>
		    </p>
		  </td>
		</tr>
	      </tbody></table>


	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	    <tr>
	    <td style="padding:20px;width:100%;vertical-align:middle">
	      <p><heading>Publications</heading></p>
	      <p>
		* indicates equal contribution. # indication corresponding author.
	      </p>
	    </td>
	  </tr>
	</tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/3DeNet.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Deformation depth decoupling network for point cloud domain adaptation</papertitle>
              <br>
		    Huang Zhang, 
		    Xin Ning, 
		    <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang*</strong></a>, 
		    Enhao Ning, 
		    Lusi Li
              <br>
              <em>Neural Networks</em>, 2024
              <br>
              <a href="https://www.sciencedirect.com/journal/neural-networks">[paper]</a>
              <br>
            </td>
		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/DIECED.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Destination intention estimation-based convolutional encoder-decoder for pedestrian trajectory multimodality forecast</papertitle>
              <br>
		Ruiping Wang, 
		Siew-Kei Lam, 
		Meiqing Wu, 
		Zhijian Hu,
		<a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang*</strong></a>, 
		Jing Wang
              <br>
              <em>Measurement</em>, 2024
              <br>
              <a href="https://www-sciencedirect-com.remotexs.ntu.edu.sg/journal/measurement">[paper]</a>
              <br>
            </td>


				  
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GPSFormer.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GPSFormer: A Global Perception and Local Structure Fitting-based Transformer for Point Cloud Understanding</papertitle>
              <br>
		<a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>, 
		Meiqing Wu, 
		Siew-Kei Lam, 
		Xin Ning,
		Ruiping Wang,
		Shangshu Yu,
		Weijun Li,
		Thambipillai Srikanthan
              <br>
              <em>ECCV</em>, 2024
              <br>
              <a href="https://github.com/changshuowang/GPSFormer">[Code]</a>
              <br>
            </td>
				  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PointGT.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>PointGT: A Method for Point-Cloud Classification and Segmentation Based on Local Geometric Transformation</papertitle>
              <br>
		Huang Zhang*, 
		<a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang*</strong></a>, 
		Long Yu, 
		Shengwei Tian, 
		Xin Ning,
		Joel Rodrigues
              <br>
              <em>IEEE Transactions on Multimedia</em>, 2024
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10462543/">[paper]</a>
              <br>
            </td>
		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/MV-3DSReID.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning</papertitle>
              <br>
		Zaiyang Yu, 
		Lusi Li, 
		Jinlong Xie, 
		<a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>, 
		Weijun Li,
		Xin Ning,
              <br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2024
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10415089/">[paper]</a>
              <br>
            </td>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/LTTPoint.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Enhancement, integration, expansion: Activating representation of detailed features for occluded person re-identification</papertitle>
              <br>
              Enhao Ning, 
	      Yangfan Wang, 
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>, 
	      Huang Zhang, 
              Xin Ning,
              <br>
              <em>Neural Networks</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0893608023006263">[paper]</a>
              <br>
            </td>

	 <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/EIE.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>LTTPoint: A MLP-Based Point Cloud Classification Method with Local Topology Transformation Module</papertitle>
              <br>
              Limin Jiang, 
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang#</strong></a>, 
              Xin Ning,
	      Zaiyang Yu
              <br>
              <em>2023 7th Asian Conference on Artificial Intelligence Technology (ACAIT)</em>, 2023
              <br>
              <a href="https://www.acaitconf.com/">[paper]</a>
              <br>
            </td>
				    
		      
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/survey_occ_preson_reid.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Occluded person re-identification with deep learning: A survey and perspectives</papertitle>
              <br>
              Enhao Ning*, 
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang*</strong></a>, 
	      Huang Zhang, 
              Xin Ning,
	      Prayag Tiwari 
              <br>
              <em>Expert Systems with Applications</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0957417423029214">[paper]</a>
              <br>
            </td>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PointReIDNet.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>3D Person Re-identification Based on Global Semantic Guidance and Local Feature Aggregation</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>, 
              Xin Ning, 
	      Weijun Li,
              Xiao Bai,
	      Xingyu Gao    
              <br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10301577">[paper]</a>
              <br>
            </td>
		

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/CECC.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Pedestrian Re-ID based on Feature Consistency and Contrast Enhancement</papertitle>
              <br>
	      Enhao Ning,
	      Canlong Zhang,
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>, 
              Xin Ning,
	      Hao Chen,
              Xiao Bai
              <br>
              <em>Displays</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0141938223001002">[paper]</a>
              <br>
            </td>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/point_survey.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Deep Learning-based 3D Point Cloud Classification: A Systematic Survey and Outlook</papertitle>
              <br>
	      Huang Zhang*, 
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong>*</a>,
	      Jianchu Lin,
	      Baoli Lu, 
	      Liping Zhang, 
              Shengwei Tian, 
              <br>
              <em>Displays</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0141938223000896">[paper]</a>
              <br>
            </td>


		
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/DC-CNN.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>3D Point Cloud Classification Method Based on Dynamic Coverage of Local Area</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>,
	      Han Wang, 
              Xin Ning,
              Shengwei Tian, 
              Weijun Li,
              <br>
              <em>Journal of Software </em>, 2022
              <br>
              <a href="https://www.jos.org.cn/josen/article/abstract/6683">[paper]</a>
              <a href="https://github.com/changshuowang/DC-CNN">[Code]</a>
              <br>
            </td>

		  
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/SC-CNN.jpg" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Discriminative Features by Covering Local Geometric Space for Point Cloud Analysis (<b>Highly Cited Paper</b>)</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>,
              Xin Ning, 
              Linjun Sun, 
              Liping Zhang, 
              Weijun Li,
              Xiao Bai
              <br>
              <em>IEEE Transactions on Geoscience and Remote Sensing (<strong>TGRS</strong>)</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9762976">[paper]</a>
              <a href="https://github.com/changshuowang/SC-CNN">[Code]</a>
              <br>
            </td>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/RGBD_survey.JPG" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>A brief survey on RGB-D semantic segmentation using deep learning</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=dsV9sgwAAAAJ&hl=en"> <strong>Changshuo Wang</strong></a>,
              Chen Wang, 
              Weijun Li,
              Haining Wang
              <br>
              <em>Displays</em>, 2021
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S014193822100086X">[paper]</a>
              <br>
            </td>

		  
          </tr>	</tbody></table>
      </div>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>AI Competitions</heading>
              <p>
	          <li style="margin: 5px;"> 2023 COSMOPlat × Extreme Mart "Tianjiao Cup" Industrial Internet Software and Application Challenge - Personnel off-post, leaving post, and boundary crossing detection  <strong>[Second Place]</strong>  </li>
	          <li style="margin: 5px;"> ECV2022 Extreme Mart Computer Vision Developer Competition - Passenger flow statistics <strong>[Third Place]</strong> </li>
	          <li style="margin: 5px;"> ECV2022 Extreme Mart Computer Vision Developer Competition - Smoking detection <strong>[Third Place]</strong>  </li>
              </p>
            </td>
          </tr>
        </tbody></table>

	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> 2023 Outstanding graduate of Beijing </li>
                <li style="margin: 5px;"> 2023 Outstanding graduate, UCAS </li>
	        <li style="margin: 5px;"> 2023 Director Scholarship from Institute of Semiconductors, CAS </li>
	        <li style="margin: 5px;"> 2022 Chinese National Scholarship </li>
	        <li style="margin: 5px;"> 2020&2021&2022 Merit Student from UCAS </li>
	        <li style="margin: 5px;"> 2019 Best Service Award from HPBD&IS </li>
	        <li style="margin: 5px;"> 2018 Outstanding Graduates of Shandong Province, China </li>
	        <li style="margin: 5px;"> 2017 Honourable Metion of MCM/ICM, USA </li>
	        <li style="margin: 5px;"> 2016 Second Prize in the 13th “Huawei Cup” National Graduate Mathematical Contest in Modeling </li>
	        <li style="margin: 5px;"> 2016 First Prize in the 8th China College Students' Mathematics Competition (Non-Mathematics Major Group) </li>
		<li style="margin: 5px;"> 2016 First Prize in the Shandong Provincial Electronic Design Contest </li>
		<li style="margin: 5px;"> 2015&2016&2017 National Encouragement scholarship from QUST </li>
              </p>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer / PC Member:</b> NeurIPS 2024, HPBD&IS 2019-2021, HDIS 2022, ICCD 2023, HDIS 2023 PC Member and Reviewer etc.
              </li>

              <li style="margin: 5px;"> 
                <b>Journal Reviewer:</b> TCSVT, Pattern recognition, Knowledge-Based Systems, Information Fusion, Neural networks, Neurocomputing, IET Computer Vision, IEEE Fuzy, Signal processing, etc.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>	
	
<a href="files/cv.pdf">A brief cv</a>.</p>
	

	

<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=yp3s8rdiQW_pbzmBOzWDx2Fv6afIlEpV-k1EZiYIkEY"></script>
	  </div>        
	  <br>
	    &copy; Changshuo Wang | Last updated: Aug 26, 2023
</center></p>
</body>

</html>
